training:
  output_dir: "./checkpoints"
  overwrite_output_dir: true
  num_train_epochs: 3
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 8
  gradient_checkpointing: true
  learning_rate: 2e-4
  weight_decay: 0.01
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  
  # Optimization
  optim: "adamw_torch"
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8
  
  # Logging and evaluation
  logging_steps: 10
  eval_steps: 100
  save_steps: 500
  evaluation_strategy: "steps"
  save_strategy: "steps"
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  save_total_limit: 3
  
  # Data processing
  max_seq_length: 2048
  dataloader_num_workers: 4
  dataloader_pin_memory: true
  remove_unused_columns: false
  
  # Mixed precision and efficiency
  fp16: false
  bf16: true
  tf32: true
  dataloader_drop_last: true
  
  # Reproducibility
  seed: 42
  data_seed: 42
  
# Stage-specific configurations
stage1_training:
  num_train_epochs: 2
  learning_rate: 1e-4
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  
stage2_training:
  num_train_epochs: 3
  learning_rate: 2e-4
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  
# DPO specific configuration
dpo_training:
  beta: 0.1
  learning_rate: 5e-7
  num_train_epochs: 1
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 16
  max_length: 2048
  max_prompt_length: 1024
  
# Evaluation configuration
evaluation:
  eval_batch_size: 4
  eval_accumulation_steps: 1
  eval_delay: 0
  include_inputs_for_metrics: true
  
# Wandb configuration
wandb:
  project: "gemma3n-therapeutic-finetuning"
  entity: null
  name: null
  tags: ["gemma3n", "therapeutic", "counseling", "motivational-interviewing"]
  notes: "Fine-tuning Gemma 3n E2B for therapeutic conversations"
